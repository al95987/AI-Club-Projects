{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ab263360",
   "metadata": {},
   "source": [
    "# Sentiment Analysis Carrying forward Module 16.2\n",
    "\n",
    "In module 16.2, we pre-processed the text. Let us now try to build a model.\n",
    "\n",
    "# 1: Importing Necessary Libraries\n",
    "\n",
    "In this cell, we'll import the necessary libraries to handle data processing and text cleaning. These include pandas for data manipulation, NLTK for natural language processing, and contractions for handling contractions in the text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbb56067",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eea315b",
   "metadata": {},
   "source": [
    "# 2: Reading Data\n",
    "\n",
    "Here we are reading the 'Tweets.csv' file into a DataFrame. We're using the 'utf-8' encoding to avoid issues with special characters.\n",
    "\n",
    "The tweets I collected were on Apple's iPhone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aebfb32c",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('indeed_scrape_clean.csv', encoding='utf-8') as f:\n",
    "    rws = pd.read_csv(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fe841b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "rws.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "687194ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "rws.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48633a85",
   "metadata": {},
   "source": [
    "By specifying the encoding as 'utf-8', you're informing the system to interpret the bytes in the file using the UTF-8 encoding, which usually handles special characters well.\n",
    "\n",
    "Make sure that the CSV file is actually encoded in UTF-8. If you still encounter issues, you may want to open the CSV file in a text editor that allows you to view and change the encoding (such as Notepad++), and make sure it's saved in UTF-8 format.\n",
    "\n",
    "# 3: Encoding Sentiment Labels\n",
    "\n",
    "First, we need to encode the sentiment labels into numerical values, as models can't handle textual labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ff32bc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Encode the sentiment column\n",
    "encoder = LabelEncoder()\n",
    "rws['sentiment_encoded'] = encoder.fit_transform(rws['sentiment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fccd040",
   "metadata": {},
   "outputs": [],
   "source": [
    "rws.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "026ce919",
   "metadata": {},
   "source": [
    "# 4: Splitting Data into Training and Testing Sets\n",
    "\n",
    "You need to convert the text into numerical form by using techniques like TF-IDF or Bag of Words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be35c5bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = rws['lemmatized'].apply(lambda x: ' '.join(eval(x)))\n",
    "y = rws['sentiment_encoded']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78aa718c",
   "metadata": {},
   "source": [
    "# 5: Text Vectorization\n",
    "\n",
    "You need to convert the text into numerical form by using techniques like TF-IDF or Bag of Words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daf70786",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer()\n",
    "X_train_vectorized = vectorizer.fit_transform(X_train)\n",
    "X_test_vectorized = vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c70c404",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_vectorized"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a056da0d",
   "metadata": {},
   "source": [
    "# 6: Building a Sentiment Analysis Model\n",
    "\n",
    "You can build a model using algorithms like Random Forest, Logistic Regression, etc. Here's an example using Logistic Regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83d44405",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression()\n",
    "model.fit(X_train_vectorized, y_train)\n",
    "\n",
    "# Making predictions\n",
    "y_pred = model.predict(X_test_vectorized)\n",
    "\n",
    "# Evaluating the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy: {accuracy}')\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7108b4ec",
   "metadata": {},
   "source": [
    "# 7: Confusion Matrix\n",
    "\n",
    "You can use confusion_matrix from sklearn.metrics to create a confusion matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27e65050",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For Logistic Regression\n",
    "y_pred = model.predict(X_test_vectorized)\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Visualization\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\")\n",
    "plt.title('Confusion matrix for Logistic Regression')\n",
    "plt.ylabel('True label')\n",
    "plt.xlabel('Predicted label')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cdd01be",
   "metadata": {},
   "source": [
    "# 8: ROC Metrics\n",
    "\n",
    "ROC curves are typically used for binary classification. If you have a multi-class problem, the ROC can be generated using either of the two options:\n",
    "\n",
    "**1.One-vs-All ROC Curve:** You can plot the ROC curve for each class against the rest. This approach treats the problem as a series of binary classification tasks.\n",
    "\n",
    "**2.Micro and Macro Averaging:** You can compute the micro and macro average ROC curves. Micro-averaging aggregates the contributions of all classes, whereas macro-averaging computes the metric independently for each class and then takes the average."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52a5d5e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Binarize the output\n",
    "y = label_binarize(y, classes=[0, 1, 2])  # Assuming you have 3 classes\n",
    "n_classes = y.shape[1]\n",
    "\n",
    "# Split into training and testing again\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Learn to predict each class against the other using the classifier of your choice\n",
    "classifier = OneVsRestClassifier(LogisticRegression())\n",
    "y_score = classifier.fit(X_train_vectorized, y_train).decision_function(X_test_vectorized)\n",
    "\n",
    "# Compute ROC curve and ROC area for each class\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "for i in range(n_classes):\n",
    "    fpr[i], tpr[i], _ = roc_curve(y_test[:, i], y_score[:, i])\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "# Plot the ROC curve\n",
    "for i in range(n_classes):\n",
    "    plt.plot(fpr[i], tpr[i], label=f'ROC curve of class {i} (area = {roc_auc[i]:0.2f})')\n",
    "\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic for Multi-Class')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8126ee38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest\n",
    "rf_model = RandomForestClassifier()\n",
    "rf_model.fit(X_train_vectorized, y_train)\n",
    "rf_y_pred = rf_model.predict(X_test_vectorized)\n",
    "rf_accuracy = accuracy_score(y_test, rf_y_pred)\n",
    "print(f'Random Forest Accuracy: {rf_accuracy}')\n",
    "print(confusion_matrix(y_test, rf_y_pred))\n",
    "print(classification_report(y_test, rf_y_pred))\n",
    "\n",
    "# Support Vector Machine\n",
    "svm_model = SVC()\n",
    "svm_model.fit(X_train_vectorized, y_train)\n",
    "svm_y_pred = svm_model.predict(X_test_vectorized)\n",
    "svm_accuracy = accuracy_score(y_test, svm_y_pred)\n",
    "print(f'SVM Accuracy: {svm_accuracy}')\n",
    "print(confusion_matrix(y_test, svm_y_pred))\n",
    "print(classification_report(y_test, svm_y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
